{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKZjIQuK10Qnv/+xm4zYpr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mechanics-Mechatronics-and-Robotics/ML-2025a/blob/main/PINN_Plates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "rmq4AfmGqdpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies for Colab\n",
        "!pip install pytorch-lightning clearml\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from clearml import Task\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from dataclasses import dataclass"
      ],
      "metadata": {
        "id": "Vv0zf7tvdX-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter your code here to implement Step 2 of the logging instruction as it is shown below\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=ZP02U03C6V5ER4K9VWRNZT7EWA5ZTV\n",
        "%env CLEARML_API_SECRET_KEY=BtA5GXZufr6QGpaqhX1GSKPTvaCt56OLqaNqUGLNoxx2Ye8Ctwbui0Ln5OXVnzUgH4I"
      ],
      "metadata": {
        "id": "WzTf35OCdkhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# üß† Theoretical Introduction: Dimensionless PINNs for Parallel Plate Flow"
      ],
      "metadata": {
        "id": "pR6UHeW91jXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider the steady, fully developed flow of an incompressible Newtonian fluid between two infinite parallel plates separated by distance \\(h\\).  \n",
        "The velocity is unidirectional along \\(x\\), varying only in the transverse direction \\(y\\), so the governing equation reduces to:\n",
        "\n",
        "$$\n",
        "\\mu \\frac{d^2 u}{dy^2} = \\frac{dp}{dx}\n",
        "$$\n",
        "\n",
        "where $\\mu$ is dynamic viscosity, $\\frac{dp}{dx}$ ‚Äî constant pressure gradient (typically negative).\n",
        "\n",
        "The **no-slip boundary conditions** are applied at both plates:\n",
        "<!--  -->\n",
        "$$\n",
        "u\\left(-\\tfrac{h}{2}\\right) = 0, \\quad u\\left(\\tfrac{h}{2}\\right) = 0\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## ‚úÖ Nondimensionalization\n",
        "\n",
        "We define dimensionless variables:\n",
        "\n",
        "$$\n",
        "Y = \\frac{y}{h}, \\qquad U = \\frac{u}{U_\\mathrm{ref}}, \\qquad\n",
        "\\Pi = \\frac{h^2}{\\mu U_\\mathrm{ref}} \\left(\\frac{dp}{dx}\\right)\n",
        "$$\n",
        "\n",
        "Substituting into the PDE gives the **dimensionless Poisson equation**:\n",
        "\n",
        "$$\n",
        "\\frac{d^2 U}{dY^2} = \\Pi\n",
        "$$\n",
        "\n",
        "with **boundary conditions**:\n",
        "\n",
        "$$\n",
        "U(-\\tfrac{1}{2}) = 0, \\quad U(\\tfrac{1}{2}) = 0\n",
        "$$\n",
        "\n",
        "The **analytic solution** in nondimensional form is:\n",
        "\n",
        "$$\n",
        "U(Y) = \\frac{\\Pi}{2} \\left( Y^2 - \\tfrac{1}{4} \\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## ‚öôÔ∏è Physics-Informed Neural Network (PINN) Formulation\n",
        "\n",
        "We approximate $U(Y)$ using a neural network $\\hat{U}(Y)$ and enforce physics via loss minimization.\n",
        "\n",
        "The total loss combines:\n",
        "\n",
        "- **PDE residual loss** ‚Äî enforcing the governing equation  \n",
        "- **Boundary loss** ‚Äî enforcing no-slip at $Y = \\pm \\tfrac{1}{2}$\n",
        "\n",
        "$$\n",
        "\\mathcal{L} =\n",
        "\\underbrace{\n",
        "\\frac{1}{N_r} \\sum_{i=1}^{N_r}\n",
        "\\left|\n",
        "\\frac{d^2 \\hat{U}}{dY^2}(Y_i) - \\Pi\n",
        "\\right|^2\n",
        "}_{\\text{Physics loss}}\n",
        "+\n",
        "\\underbrace{\n",
        "\\frac{1}{N_b} \\sum_{j=1}^{N_b}\n",
        "\\left|\n",
        "\\hat{U}(Y_j) - U_j\n",
        "\\right|^2\n",
        "}_{\\text{Boundary loss}}\n",
        "$$"
      ],
      "metadata": {
        "id": "zfEqnjmA1U3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Config"
      ],
      "metadata": {
        "id": "5W0GIK3r9o7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_dtype(torch.float32)\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    # Physics parameters for dimensionalization\n",
        "    h: float = 1e-3                # channel height [m]\n",
        "    mu: float = 1e-3               # dynamic viscosity [Pa¬∑s]\n",
        "    rho: float = 1e+3              # density [kg / m^3]\n",
        "    dpdx: float = -1e+3        # pressure gradient [Pa/m]\n",
        "\n",
        "    # training hyperparams\n",
        "    lr: float = 1e-3\n",
        "    epochs: int = 1000\n",
        "    n_colloc_per_Y: int = 64       # spatial points per batch\n",
        "    n_boundary_per_Y: int = 2      # boundary points (fixed: Y=-0.5, 0.5)\n",
        "    batch_size_pi: int = 20         # number of Pi values per batch\n",
        "    n_pi_total: int = 100          # total number of Pi values\n",
        "    pi_min: float = 1e-0\n",
        "    pi_max: float = 1e+1\n",
        "\n",
        "    # data split ratios\n",
        "    train_ratio: float = 0.6\n",
        "    val_ratio: float = 0.2\n",
        "    test_ratio: float = 0.2\n",
        "\n",
        "    # network\n",
        "    layers: tuple = (2, 64, 64, 64, 64, 1)\n",
        "\n",
        "    # settings\n",
        "    check_val_every_n_epoch: int = 100\n",
        "    task_name: str = \"PINN_plates_dimless_generalized\"\n",
        "\n",
        "cfg = Config()"
      ],
      "metadata": {
        "id": "QFz8oQCQ9mXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Dataset and Dataloaders"
      ],
      "metadata": {
        "id": "8jjgp93wWOCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Dataset Classes\n",
        "# ----------------------------\n",
        "class PiSpatialDataset(Dataset):\n",
        "    \"\"\"Dataset that returns batches of spatial points for specific Pi values\"\"\"\n",
        "    def __init__(self, pi_values, n_colloc_per_Y, n_boundary_per_Y, device):\n",
        "        self.pi_values = pi_values\n",
        "        self.n_colloc_per_Y = n_colloc_per_Y\n",
        "        self.n_boundary_per_Y = n_boundary_per_Y\n",
        "        self.device = device\n",
        "\n",
        "        # Precompute spatial grids\n",
        "        self.Y_colloc = torch.linspace(-0.5, 0.5, n_colloc_per_Y, device=device).reshape(-1, 1)\n",
        "        self.Y_boundary = torch.tensor([[-0.5], [0.5]], device=device, dtype=torch.float32)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pi_values)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        pi = self.pi_values[idx]\n",
        "\n",
        "        # Collocation points\n",
        "        Y_colloc_batch = self.Y_colloc\n",
        "        Pi_colloc_batch = torch.full_like(Y_colloc_batch, pi)\n",
        "        X_colloc = torch.cat([Y_colloc_batch, Pi_colloc_batch], dim=1)\n",
        "\n",
        "        # Boundary points\n",
        "        Y_boundary_batch = self.Y_boundary\n",
        "        Pi_boundary_batch = torch.full_like(Y_boundary_batch, pi)\n",
        "        X_boundary = torch.cat([Y_boundary_batch, Pi_boundary_batch], dim=1)\n",
        "        U_boundary = torch.zeros_like(Y_boundary_batch)\n",
        "\n",
        "        return X_colloc, X_boundary, U_boundary\n",
        "\n",
        "class PiBatchDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, cfg: Config, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.device = device\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        # Generate Pi values\n",
        "        n_total = self.cfg.n_pi_total\n",
        "        self.pi_all = torch.linspace(\n",
        "            self.cfg.pi_min, self.cfg.pi_max, n_total, device=self.device\n",
        "        )\n",
        "\n",
        "        # Split into train/val/test\n",
        "        n_train = int(n_total * self.cfg.train_ratio)\n",
        "        n_val = int(n_total * self.cfg.val_ratio)\n",
        "        n_test = n_total - n_train - n_val\n",
        "\n",
        "        # Shuffle indices\n",
        "        indices = torch.randperm(n_total)\n",
        "        train_idx = indices[:n_train]\n",
        "        val_idx = indices[n_train:n_train + n_val]\n",
        "        test_idx = indices[n_train + n_val:]\n",
        "\n",
        "        self.pi_train = self.pi_all[train_idx]\n",
        "        self.pi_val = self.pi_all[val_idx]\n",
        "        self.pi_test = self.pi_all[test_idx]\n",
        "\n",
        "        print(f\"Dataset sizes - Train: {len(self.pi_train)}, Val: {len(self.pi_val)}, Test: {len(self.pi_test)}\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        dataset = PiSpatialDataset(\n",
        "            self.pi_train,\n",
        "            self.cfg.n_colloc_per_Y,\n",
        "            self.cfg.n_boundary_per_Y,\n",
        "            self.device\n",
        "        )\n",
        "        return DataLoader(dataset, batch_size=self.cfg.batch_size_pi,\n",
        "                          num_workers=0, shuffle=True)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        dataset = PiSpatialDataset(\n",
        "            self.pi_val,\n",
        "            self.cfg.n_colloc_per_Y,\n",
        "            self.cfg.n_boundary_per_Y,\n",
        "            self.device\n",
        "        )\n",
        "        return DataLoader(dataset, batch_size=self.cfg.batch_size_pi,\n",
        "                          num_workers=0, shuffle=False)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        dataset = PiSpatialDataset(\n",
        "            self.pi_test,\n",
        "            self.cfg.n_colloc_per_Y,\n",
        "            self.cfg.n_boundary_per_Y,\n",
        "            self.device\n",
        "        )\n",
        "        return DataLoader(dataset, batch_size=self.cfg.batch_size_pi, shuffle=False)"
      ],
      "metadata": {
        "id": "uQuJE-dpWQum"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "u1IQaLWMqjMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "task = Task.init(\n",
        "    project_name=\"PINN_Project\",   # choose a descriptive project name\n",
        "    task_name=cfg.task_name,  # descriptive task name\n",
        ")\n",
        "\n",
        "# task.connect(params)\n",
        "tb_logger = TensorBoardLogger(\n",
        "    save_dir=\"logs\",  # ClearML will automatically monitor this\n",
        "    name=cfg.task_name,\n",
        "    # version=f\"bs_{HP['batch_size']}_lr_{HP['lr_simclr']}\"\n",
        "  )\n",
        "\n",
        "# ----------------------------\n",
        "# PINN Model\n",
        "# ----------------------------\n",
        "class PINN(pl.LightningModule):\n",
        "    def __init__(self, layers, lr):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.lr = lr\n",
        "        self.net = self._build_mlp(layers)\n",
        "\n",
        "    def _build_mlp(self, sizes):\n",
        "        layers = []\n",
        "        for i in range(len(sizes)-1):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if i < len(sizes)-2:\n",
        "                layers.append(nn.Tanh())\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.net(X)\n",
        "\n",
        "    def _second_deriv_wrt_Y(self, X):\n",
        "        X_temp = X.clone().requires_grad_(True)\n",
        "        U = self.forward(X_temp)\n",
        "\n",
        "        # First derivative wrt Y\n",
        "        dU_dY = torch.autograd.grad(\n",
        "            U, X_temp,\n",
        "            grad_outputs=torch.ones_like(U),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0][:, 0:1]\n",
        "\n",
        "        # Second derivative wrt Y\n",
        "        d2U_dY2 = torch.autograd.grad(\n",
        "            dU_dY, X_temp,\n",
        "            grad_outputs=torch.ones_like(dU_dY),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0][:, 0:1]\n",
        "\n",
        "        return d2U_dY2\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        X_colloc, X_bc, U_bc = batch\n",
        "\n",
        "        # Reshape batches: [batch_size_pi * n_points, 2]\n",
        "        batch_size_pi = X_colloc.shape[0]\n",
        "        n_colloc = X_colloc.shape[1]\n",
        "        n_bc = X_bc.shape[1]\n",
        "\n",
        "        X_colloc_flat = X_colloc.reshape(-1, 2)\n",
        "        X_bc_flat = X_bc.reshape(-1, 2)\n",
        "        U_bc_flat = U_bc.reshape(-1, 1)\n",
        "\n",
        "        # PDE residual loss\n",
        "        res = self._pde_residual(X_colloc_flat)\n",
        "        pde_loss = torch.mean(res**2)\n",
        "        # constraint = torch.mean(res)\n",
        "\n",
        "        # Boundary loss\n",
        "        U_pred_bc = self.forward(X_bc_flat)\n",
        "        bc_loss = nn.functional.mse_loss(U_pred_bc, U_bc_flat)\n",
        "\n",
        "        loss = pde_loss + bc_loss #+ constraint\n",
        "        #  + 0.01 * physical_constraint_loss\n",
        "        self.log_dict({\n",
        "            \"train_pde\": pde_loss,\n",
        "            \"train_bc\": bc_loss,\n",
        "            # \"train_pc\": physical_constraint_loss,\n",
        "            \"train_loss\": loss\n",
        "        }, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def _pde_residual(self, X_colloc):\n",
        "        U_YY = self._second_deriv_wrt_Y(X_colloc)\n",
        "        Pi = X_colloc[:, 1:2]\n",
        "        res = U_YY - Pi\n",
        "        return res\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        X_colloc, X_bc, U_bc = batch\n",
        "\n",
        "        # Flatten batches\n",
        "        X_colloc_flat = X_colloc.reshape(-1, 2)\n",
        "        X_bc_flat = X_bc.reshape(-1, 2)\n",
        "        U_bc_flat = U_bc.reshape(-1, 1)\n",
        "\n",
        "        with torch.enable_grad():\n",
        "            res = self._pde_residual(X_colloc_flat)\n",
        "            pde_loss = torch.mean(res ** 2)\n",
        "            # constraint = torch.mean(res)\n",
        "            U_pred_bc = self.forward(X_bc_flat)\n",
        "            bc_loss = nn.functional.mse_loss(U_pred_bc, U_bc_flat)\n",
        "            val_loss = pde_loss + bc_loss# + constraint\n",
        "\n",
        "        self.log_dict({\n",
        "            \"val_pde\": pde_loss,\n",
        "            \"val_bc\": bc_loss,\n",
        "            \"val_loss\": val_loss\n",
        "        }, prog_bar=True)\n",
        "        return val_loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr, weight_decay=1e-5)\n",
        "\n",
        "# ----------------------------\n",
        "# Dimensionalization Utilities\n",
        "# ----------------------------\n",
        "def dimensionless_to_dimensional(U_dim, Y_dim, Pi, cfg):\n",
        "    \"\"\"Convert dimensionless results to dimensional\"\"\"\n",
        "    # Velocity: u = U * U_ref\n",
        "    U_ref = (cfg.h**2 * cfg.dpdx) / (cfg.mu * Pi)\n",
        "    u_dimensional = U_dim * U_ref\n",
        "\n",
        "    # Position: y = Y * h\n",
        "    y_dimensional = Y_dim * cfg.h\n",
        "\n",
        "    return u_dimensional, y_dimensional, cfg.dpdx\n",
        "\n",
        "def analytical_solution_dimensional(y, dpdx, mu, h):\n",
        "    \"\"\"Analytical solution for dimensional velocity\"\"\"\n",
        "    # u(y) = (1/(2Œº)) * (dp/dx) * (y¬≤ - (h/2)¬≤)\n",
        "    return (1/(2*mu)) * dpdx * (y**2 - (h/2)**2)\n",
        "\n",
        "# ----------------------------\n",
        "# Training\n",
        "# ----------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dm = PiBatchDataModule(cfg, device=device)\n",
        "dm.setup()\n",
        "\n",
        "model = PINN(layers=cfg.layers, lr=cfg.lr)\n",
        "\n",
        "ckpt_cb = ModelCheckpoint(\n",
        "    dirpath=\"checkpoints\",\n",
        "    filename=\"pinn_best\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=cfg.epochs,\n",
        "    accelerator=\"auto\",\n",
        "    callbacks=[ckpt_cb],\n",
        "    log_every_n_steps=50,\n",
        "    check_val_every_n_epoch=cfg.check_val_every_n_epoch\n",
        ")\n",
        "\n",
        "trainer.fit(model, datamodule=dm)\n"
      ],
      "metadata": {
        "id": "OSNGxk4Qu5oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task.close()"
      ],
      "metadata": {
        "id": "_a8VvG3p4YXa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Testing and Results\n",
        "# ----------------------------\n",
        "best_model = PINN.load_from_checkpoint(ckpt_cb.best_model_path, layers=cfg.layers, lr=cfg.lr)\n",
        "best_model.eval()\n",
        "best_model = best_model.to(device)\n",
        "\n",
        "# Test on various Pi values\n",
        "test_pi_values = np.linspace(cfg.pi_min, cfg.pi_max, 6)\n",
        "Y_test = torch.linspace(-0.5, 0.5, 100, device=device).reshape(-1, 1)\n",
        "\n",
        "# Results tables\n",
        "dimensionless_results = []\n",
        "dimensional_results = []\n",
        "detailed_results = []\n",
        "\n",
        "# Calculate U_ref for each Pi and Reynolds number\n",
        "def calculate_reynolds(pi, cfg):\n",
        "    \"\"\"Calculate Reynolds number for given Pi\"\"\"\n",
        "    # From Pi definition: Œ† = (h¬≤/(Œº¬∑U_ref)) * (dp/dx)\n",
        "    # So U_ref = (h¬≤ * |dp/dx|) / (Œº * Œ†)  [taking absolute value for Re calculation]\n",
        "    U_ref = (cfg.h**2 * cfg.dpdx) / (cfg.mu * pi)\n",
        "    Re = (cfg.rho * abs(U_ref) * cfg.h) / cfg.mu\n",
        "    return Re, U_ref\n",
        "\n",
        "# Create comprehensive plots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "colors = plt.cm.viridis(np.linspace(0, 1, len(test_pi_values)))\n",
        "\n",
        "# Plot 1: Dimensionless velocity profiles\n",
        "ax1 = axes[0, 0]\n",
        "for i, pi in enumerate(test_pi_values):\n",
        "    Pi_test = torch.full_like(Y_test, pi)\n",
        "    X_test = torch.cat([Y_test, Pi_test], dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        U_pred_dimless = best_model(X_test).cpu().numpy().flatten()\n",
        "\n",
        "    U_analytical_dimless = (pi/2.0) * (Y_test.cpu().numpy().flatten()**2 - 0.25)\n",
        "\n",
        "    # Solid line for PINN, crosses for analytical\n",
        "    ax1.plot(Y_test.cpu().numpy(), U_pred_dimless, '-', color=colors[i], linewidth=2, label=f'PINN Œ†={pi}')\n",
        "    ax1.plot(Y_test.cpu().numpy(), U_analytical_dimless, 'x', color=colors[i], markersize=4, label=f'Analytical Œ†={pi}')\n",
        "\n",
        "ax1.set_xlabel('Y (Dimensionless)')\n",
        "ax1.set_ylabel('U (Dimensionless)')\n",
        "ax1.set_title('Dimensionless Velocity Profiles')\n",
        "ax1.legend()\n",
        "ax1.grid(True)\n",
        "\n",
        "# Plot 2: Dimensional velocity profiles\n",
        "ax2 = axes[0, 1]\n",
        "for i, pi in enumerate(test_pi_values):\n",
        "    Pi_test = torch.full_like(Y_test, pi)\n",
        "    X_test = torch.cat([Y_test, Pi_test], dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        U_pred_dimless = best_model(X_test).cpu().numpy().flatten()\n",
        "\n",
        "    # Calculate U_ref for this Pi\n",
        "    Re, U_ref = calculate_reynolds(pi, cfg)\n",
        "\n",
        "    # Convert to dimensional\n",
        "    u_pred_dimensional = U_pred_dimless * U_ref\n",
        "    y_dimensional = Y_test.cpu().numpy().flatten() * cfg.h\n",
        "\n",
        "    # Analytical solution in dimensional form\n",
        "    u_analytical_dimensional = analytical_solution_dimensional(\n",
        "        y_dimensional, cfg.dpdx, cfg.mu, cfg.h\n",
        "    )\n",
        "\n",
        "    ax2.plot(y_dimensional, u_pred_dimensional, '-', color=colors[i], linewidth=2, label=f'PINN Œ†={pi}')\n",
        "    ax2.plot(y_dimensional, u_analytical_dimensional, 'x', color=colors[i], markersize=4, label=f'Analytical Œ†={pi}')\n",
        "\n",
        "ax2.set_xlabel('y [m]')\n",
        "ax2.set_ylabel('u [m/s]')\n",
        "ax2.set_title('Dimensional Velocity Profiles')\n",
        "ax2.legend()\n",
        "ax2.grid(True)\n",
        "\n",
        "# Plot 3: Absolute velocity error (dimensionless)\n",
        "ax3 = axes[1, 0]\n",
        "for i, pi in enumerate(test_pi_values):\n",
        "    Pi_test = torch.full_like(Y_test, pi)\n",
        "    X_test = torch.cat([Y_test, Pi_test], dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        U_pred_dimless = best_model(X_test).cpu().numpy().flatten()\n",
        "\n",
        "    U_analytical_dimless = (pi/2.0) * (Y_test.cpu().numpy().flatten()**2 - 0.25)\n",
        "\n",
        "    absolute_error = np.abs(U_pred_dimless - U_analytical_dimless)\n",
        "\n",
        "    ax3.plot(Y_test.cpu().numpy(), absolute_error, '-', color=colors[i], linewidth=2, label=f'Œ†={pi}')\n",
        "\n",
        "ax3.set_xlabel('Y (Dimensionless)')\n",
        "ax3.set_ylabel('Absolute Error (Dimensionless)')\n",
        "ax3.set_title('Absolute Velocity Error (Dimensionless)')\n",
        "ax3.legend()\n",
        "ax3.grid(True)\n",
        "\n",
        "# Plot 4: Error distribution across Pi values\n",
        "ax4 = axes[1, 1]\n",
        "max_errors = []\n",
        "center_errors = []\n",
        "for pi in test_pi_values:\n",
        "    Pi_test = torch.full_like(Y_test, pi)\n",
        "    X_test = torch.cat([Y_test, Pi_test], dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        U_pred_dimless = best_model(X_test).cpu().numpy().flatten()\n",
        "\n",
        "    U_analytical_dimless = (pi/2.0) * (0.25 - Y_test.cpu().numpy().flatten()**2)\n",
        "\n",
        "    max_error = np.max(np.abs(U_pred_dimless - U_analytical_dimless))\n",
        "    center_error = np.abs(U_pred_dimless[50] - U_analytical_dimless[50])\n",
        "\n",
        "    max_errors.append(max_error)\n",
        "    center_errors.append(center_error)\n",
        "\n",
        "ax4.plot(test_pi_values, max_errors, 'o-', linewidth=2, label='Max Error')\n",
        "ax4.plot(test_pi_values, center_errors, 's-', linewidth=2, label='Center Error')\n",
        "ax4.set_xlabel('Œ†')\n",
        "ax4.set_ylabel('Error (Dimensionless)')\n",
        "ax4.set_title('Error vs Œ†')\n",
        "ax4.legend()\n",
        "ax4.grid(True)\n",
        "ax4.set_yscale('log')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Calculate detailed results with Reynolds numbers\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"COMPREHENSIVE TEST RESULTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for pi in test_pi_values:\n",
        "    Pi_test = torch.full_like(Y_test, pi)\n",
        "    X_test = torch.cat([Y_test, Pi_test], dim=1)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        U_pred_dimless = best_model(X_test).cpu().numpy().flatten()\n",
        "\n",
        "    U_analytical_dimless = (pi/2.0) * (Y_test.cpu().numpy().flatten()**2 - 0.25)\n",
        "\n",
        "    # Calculate Reynolds number and U_ref\n",
        "    Re, U_ref = calculate_reynolds(pi, cfg)\n",
        "\n",
        "    # Convert to dimensional\n",
        "    u_pred_dimensional = U_pred_dimless * U_ref\n",
        "    u_analytical_dimensional = U_analytical_dimless * U_ref\n",
        "    y_dimensional = Y_test.cpu().numpy().flatten() * cfg.h\n",
        "\n",
        "    # Errors\n",
        "    mse_dimless = np.mean((U_pred_dimless - U_analytical_dimless)**2)\n",
        "    max_error_dimless = np.max(np.abs(U_pred_dimless - U_analytical_dimless))\n",
        "\n",
        "    mse_dimensional = np.mean((u_pred_dimensional - u_analytical_dimensional)**2)\n",
        "    max_error_dimensional = np.max(np.abs(u_pred_dimensional - u_analytical_dimensional))\n",
        "\n",
        "    # Maximum velocity (at center)\n",
        "    max_u_pred = U_pred_dimless[50]  # Y=0\n",
        "    max_u_analytical = U_analytical_dimless[50]\n",
        "    max_u_error = abs(max_u_pred - max_u_analytical)\n",
        "\n",
        "    max_u_pred_dimensional = u_pred_dimensional[50]\n",
        "    max_u_analytical_dimensional = u_analytical_dimensional[50]\n",
        "    max_u_error_dimensional = abs(max_u_pred_dimensional - max_u_analytical_dimensional)\n",
        "\n",
        "    dimensionless_results.append({\n",
        "        \"Pi\": pi,\n",
        "        \"MSE\": mse_dimless,\n",
        "        \"Max_Error\": max_error_dimless,\n",
        "        \"U_pred_center\": max_u_pred,\n",
        "        \"U_analytical_center\": max_u_analytical,\n",
        "        \"Error_center\": max_u_error\n",
        "    })\n",
        "\n",
        "    dimensional_results.append({\n",
        "        \"Pi\": pi,\n",
        "        \"U_ref [m/s]\": U_ref,\n",
        "        \"Re\": Re,\n",
        "        \"MSE [m¬≤/s¬≤]\": mse_dimensional,\n",
        "        \"Max_Error [m/s]\": max_error_dimensional,\n",
        "        \"u_pred_center [m/s]\": max_u_pred_dimensional,\n",
        "        \"u_analytical_center [m/s]\": max_u_analytical_dimensional,\n",
        "        \"Error_center [m/s]\": max_u_error_dimensional\n",
        "    })\n",
        "\n",
        "    detailed_results.append({\n",
        "        \"#\": len(detailed_results) + 1,\n",
        "        \"Pi\": pi,\n",
        "        \"Re\": f\"{Re:.2f}\",\n",
        "        \"Max_U_Pred\": f\"{max_u_pred:.6f}\",\n",
        "        \"Max_U_Analytical\": f\"{max_u_analytical:.6f}\",\n",
        "        \"Max_U_Error\": f\"{max_u_error:.6f}\",\n",
        "        \"MSE\": f\"{mse_dimless:.6f}\"\n",
        "    })\n",
        "\n",
        "# Print detailed table with Re numbers\n",
        "print(\"\\nDETAILED DIMENSIONLESS RESULTS WITH REYNOLDS NUMBERS\")\n",
        "print(\"=\"*80)\n",
        "detailed_df = pd.DataFrame(detailed_results)\n",
        "print(detailed_df.to_string(index=False))\n",
        "\n",
        "# Print dimensionless results\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DIMENSIONLESS RESULTS\")\n",
        "print(\"=\"*80)\n",
        "df_dimensionless = pd.DataFrame(dimensionless_results)\n",
        "pd.set_option(\"display.float_format\", \"{:.6e}\".format)\n",
        "print(df_dimensionless.to_string(index=False))\n",
        "\n",
        "# Print dimensional results\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"DIMENSIONAL RESULTS\")\n",
        "print(\"=\"*80)\n",
        "df_dimensional = pd.DataFrame(dimensional_results)\n",
        "print(df_dimensional.to_string(index=False))\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"SUMMARY STATISTICS\")\n",
        "print(\"=\"*80)\n",
        "print(f\"Training Pi range: {cfg.pi_min} to {cfg.pi_max}\")\n",
        "print(f\"Test Pi values: {test_pi_values}\")\n",
        "print(f\"Physical parameters: h={cfg.h} m, Œº={cfg.mu} Pa¬∑s, œÅ={cfg.rho} kg/m¬≥, dp/dx={cfg.dpdx} Pa/m\")\n",
        "print(f\"\\nDimensionless Max Error across all tests: {max(r['Max_Error'] for r in dimensionless_results):.2e}\")\n",
        "print(f\"Dimensional Max Error across all tests: {max(r['Max_Error [m/s]'] for r in dimensional_results):.2e} m/s\")\n",
        "\n",
        "# Reynolds number analysis\n",
        "print(f\"\\nReynolds Number Range: {min(float(r['Re']) for r in dimensional_results):.2f} to {max(float(r['Re']) for r in dimensional_results):.2f}\")\n",
        "\n",
        "# Test on validation and test sets\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"VALIDATION AND TEST SET PERFORMANCE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "def evaluate_dataset(pi_values, dataset_name):\n",
        "    total_mse = 0\n",
        "    total_max_error = 0\n",
        "    count = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for pi in pi_values[:10]:  # Evaluate on first 10 values\n",
        "            Pi_test = torch.full_like(Y_test, pi.item())\n",
        "            X_test = torch.cat([Y_test, Pi_test], dim=1)\n",
        "\n",
        "            U_pred_dimless = best_model(X_test).cpu().numpy().flatten()\n",
        "            U_analytical_dimless = (pi.item()/2.0) * (Y_test.cpu().numpy().flatten()**2 - 0.25)\n",
        "\n",
        "            mse = np.mean((U_pred_dimless - U_analytical_dimless)**2)\n",
        "            max_error = np.max(np.abs(U_pred_dimless - U_analytical_dimless))\n",
        "\n",
        "            total_mse += mse\n",
        "            total_max_error += max_error\n",
        "            count += 1\n",
        "\n",
        "    avg_mse = total_mse / count\n",
        "    avg_max_error = total_max_error / count\n",
        "    print(f\"{dataset_name} set - Avg MSE: {avg_mse:.2e}, Avg Max Error: {avg_max_error:.2e}\")\n",
        "\n",
        "evaluate_dataset(dm.pi_train, \"Train\")\n",
        "evaluate_dataset(dm.pi_val, \"Validation\")\n",
        "evaluate_dataset(dm.pi_test, \"Test\")\n",
        "\n",
        "# Additional analysis: Check if the model learned the physical relationship\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"PHYSICAL RELATIONSHIP ANALYSIS\")\n",
        "print(\"=\"*80)\n",
        "print(\"Checking if U_max ‚àù Œ† (should be linear relationship):\")\n",
        "\n",
        "# Extract max velocities vs Pi\n",
        "pi_values_analysis = np.array([r['Pi'] for r in dimensionless_results])\n",
        "max_u_values = np.array([r['U_pred_center'] for r in dimensionless_results])\n",
        "max_u_analytical = np.array([r['U_analytical_center'] for r in dimensionless_results])\n",
        "\n",
        "# Calculate linear regression for predicted values\n",
        "slope_pred, intercept_pred = np.polyfit(pi_values_analysis, max_u_values, 1)\n",
        "slope_analytical, intercept_analytical = np.polyfit(pi_values_analysis, max_u_analytical, 1)\n",
        "\n",
        "print(f\"Predicted relationship: U_max = {slope_pred:.6f} * Œ† + {intercept_pred:.6f}\")\n",
        "print(f\"Analytical relationship: U_max = {slope_analytical:.6f} * Œ† + {intercept_analytical:.6f}\")\n",
        "print(f\"Slope error: {abs(slope_pred - slope_analytical)/slope_analytical*100:.2f}%\")\n",
        "\n",
        "# Plot the relationship\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(pi_values_analysis, max_u_values, 'bo-', label='PINN Prediction', linewidth=2)\n",
        "plt.plot(pi_values_analysis, max_u_analytical, 'rx-', label='Analytical', linewidth=2)\n",
        "plt.plot(pi_values_analysis, slope_pred * pi_values_analysis + intercept_pred, 'b--', alpha=0.5, label=f'PINN Fit: slope={slope_pred:.4f}')\n",
        "plt.plot(pi_values_analysis, slope_analytical * pi_values_analysis + intercept_analytical, 'r--', alpha=0.5, label=f'Analytical: slope={slope_analytical:.4f}')\n",
        "plt.xlabel('Œ†')\n",
        "plt.ylabel('U_max (at Y=0)')\n",
        "plt.title('Maximum Velocity vs Œ† (Checking Physical Relationship)')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "YdnBoNg-26Qa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Batch Inspection Code\n",
        "# ----------------------------\n",
        "print(\"=\" * 80)\n",
        "print(\"BATCH STRUCTURE INSPECTION\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "# Get the first batch from train dataloader\n",
        "train_dataloader = dm.train_dataloader()\n",
        "first_batch = next(iter(train_dataloader))\n",
        "\n",
        "print(\"Batch type:\", type(first_batch))\n",
        "print(\"Number of elements in batch:\", len(first_batch))\n",
        "print(\"\\n\")\n",
        "\n",
        "# Unpack the batch\n",
        "X_colloc, X_bc, U_bc = first_batch\n",
        "\n",
        "print(\"1. COLLOCATION POINTS (X_colloc)\")\n",
        "print(\"   Shape:\", X_colloc.shape)\n",
        "print(\"   dtype:\", X_colloc.dtype)\n",
        "print(\"   device:\", X_colloc.device)\n",
        "print(\"\\n   First 5 elements:\")\n",
        "print(\"   \" + \"=\" * 50)\n",
        "for i in range(min(5, X_colloc.shape[0])):\n",
        "    print(f\"   Batch element {i}:\")\n",
        "    print(f\"     Shape: {X_colloc[i].shape}\")\n",
        "    print(f\"     First 3 collocation points:\")\n",
        "    for j in range(min(3, X_colloc[i].shape[0])):\n",
        "        y_val = X_colloc[i][j, 0].item()\n",
        "        pi_val = X_colloc[i][j, 1].item()\n",
        "        print(f\"       Point {j}: Y = {y_val:8.4f}, Œ† = {pi_val:8.4f}\")\n",
        "    print()\n",
        "\n",
        "print(\"\\n2. BOUNDARY POINTS (X_bc)\")\n",
        "print(\"   Shape:\", X_bc.shape)\n",
        "print(\"   dtype:\", X_bc.dtype)\n",
        "print(\"   device:\", X_bc.device)\n",
        "print(\"\\n   First 5 batch elements:\")\n",
        "print(\"   \" + \"=\" * 50)\n",
        "for i in range(min(5, X_bc.shape[0])):\n",
        "    print(f\"   Batch element {i}:\")\n",
        "    print(f\"     Shape: {X_bc[i].shape}\")\n",
        "    print(f\"     Boundary points:\")\n",
        "    for j in range(X_bc[i].shape[0]):\n",
        "        y_val = X_bc[i][j, 0].item()\n",
        "        pi_val = X_bc[i][j, 1].item()\n",
        "        print(f\"       Y = {y_val:8.4f}, Œ† = {pi_val:8.4f}\")\n",
        "    print()\n",
        "\n",
        "print(\"\\n3. BOUNDARY VALUES (U_bc)\")\n",
        "print(\"   Shape:\", U_bc.shape)\n",
        "print(\"   dtype:\", U_bc.dtype)\n",
        "print(\"   device:\", U_bc.device)\n",
        "print(\"\\n   First 5 batch elements:\")\n",
        "print(\"   \" + \"=\" * 50)\n",
        "for i in range(min(5, U_bc.shape[0])):\n",
        "    print(f\"   Batch element {i}:\")\n",
        "    print(f\"     Shape: {U_bc[i].shape}\")\n",
        "    print(f\"     Boundary values (should all be 0):\")\n",
        "    for j in range(U_bc[i].shape[0]):\n",
        "        u_val = U_bc[i][j, 0].item()\n",
        "        print(f\"       U = {u_val:8.4f}\")\n",
        "    print()\n",
        "\n",
        "# Additional analysis: Check unique Pi values in this batch\n",
        "print(\"\\n4. BATCH ANALYSIS\")\n",
        "print(\"   \" + \"=\" * 50)\n",
        "\n",
        "# Extract all Pi values from collocation points\n",
        "all_pi_values = []\n",
        "for i in range(X_colloc.shape[0]):\n",
        "    # All points in this batch element have the same Pi value\n",
        "    pi_val = X_colloc[i][0, 1].item()\n",
        "    all_pi_values.append(pi_val)\n",
        "\n",
        "print(f\"   Number of unique Œ† values in batch: {len(set(all_pi_values))}\")\n",
        "print(f\"   Œ† values in this batch: {sorted(set(all_pi_values))}\")\n",
        "print(f\"   Œ† range in batch: min={min(all_pi_values):.4f}, max={max(all_pi_values):.4f}\")\n",
        "\n",
        "# Check spatial distribution for first Pi value\n",
        "first_pi = all_pi_values[0]\n",
        "print(f\"\\n   Spatial distribution for Œ† = {first_pi:.4f}:\")\n",
        "first_batch_colloc = X_colloc[0]\n",
        "y_values = first_batch_colloc[:, 0].cpu().numpy()\n",
        "print(f\"     Y range: min={y_values.min():.4f}, max={y_values.max():.4f}\")\n",
        "print(f\"     Number of collocation points: {len(y_values)}\")\n",
        "print(f\"     Y spacing: ~{(y_values.max() - y_values.min()) / len(y_values):.4f}\")\n",
        "\n",
        "# Verify boundary conditions\n",
        "print(f\"\\n   Boundary condition verification for Œ† = {first_pi:.4f}:\")\n",
        "first_batch_bc = X_bc[0]\n",
        "first_batch_u_bc = U_bc[0]\n",
        "for j in range(first_batch_bc.shape[0]):\n",
        "    y_val = first_batch_bc[j, 0].item()\n",
        "    u_val = first_batch_u_bc[j, 0].item()\n",
        "    print(f\"     Y = {y_val:8.4f}, U = {u_val:8.4f} (should be 0)\")\n",
        "\n",
        "# Test the model on the first batch element\n",
        "print(\"\\n5. MODEL PREDICTION ON FIRST BATCH ELEMENT\")\n",
        "print(\"   \" + \"=\" * 50)\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Flatten the first batch element for prediction\n",
        "    X_colloc_flat = X_colloc[0]  # Shape: [n_colloc_per_Y, 2]\n",
        "    predictions = best_model(X_colloc_flat)\n",
        "\n",
        "    print(f\"   Input shape: {X_colloc_flat.shape}\")\n",
        "    print(f\"   Output shape: {predictions.shape}\")\n",
        "    print(f\"   Œ† value: {first_pi:.4f}\")\n",
        "    print(f\"   Prediction range: min={predictions.min().item():.6f}, max={predictions.max().item():.6f}\")\n",
        "    print(f\"   First 5 predictions:\")\n",
        "    for j in range(min(5, predictions.shape[0])):\n",
        "        y_val = X_colloc_flat[j, 0].item()\n",
        "        pred_val = predictions[j, 0].item()\n",
        "        print(f\"     Y = {y_val:8.4f}, U_pred = {pred_val:10.6f}\")\n",
        "\n",
        "# Compare with analytical solution for the first Pi value\n",
        "print(f\"\\n6. COMPARISON WITH ANALYTICAL SOLUTION FOR Œ† = {first_pi:.4f}\")\n",
        "print(\"   \" + \"=\" * 50)\n",
        "\n",
        "analytical_solution = (first_pi/2.0) * (X_colloc_flat[:, 0].cpu().numpy()**2 - 0.25)\n",
        "\n",
        "print(\"   First 5 points comparison:\")\n",
        "print(\"   \" + \"-\" * 60)\n",
        "print(\"      Y        U_PINN       U_Analytical     Error\")\n",
        "print(\"   \" + \"-\" * 60)\n",
        "for j in range(min(5, predictions.shape[0])):\n",
        "    y_val = X_colloc_flat[j, 0].item()\n",
        "    pred_val = predictions[j, 0].item()\n",
        "    analytical_val = analytical_solution[j]\n",
        "    error = abs(pred_val - analytical_val)\n",
        "    print(f\"   {y_val:8.4f}   {pred_val:12.6f}   {analytical_val:12.6f}   {error:12.6f}\")\n",
        "\n",
        "# Calculate overall error for this batch element\n",
        "mse_batch = torch.mean((predictions.squeeze() - torch.tensor(analytical_solution, device=predictions.device))**2).item()\n",
        "max_error_batch = torch.max(torch.abs(predictions.squeeze() - torch.tensor(analytical_solution, device=predictions.device))).item()\n",
        "\n",
        "print(f\"\\n   Overall error for this batch element:\")\n",
        "print(f\"     MSE: {mse_batch:.6e}\")\n",
        "print(f\"     Max Error: {max_error_batch:.6e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 80)\n",
        "print(\"BATCH INSPECTION COMPLETE\")\n",
        "print(\"=\" * 80)"
      ],
      "metadata": {
        "id": "Mq8Dtt3tjYrz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
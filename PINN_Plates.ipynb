{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOQOuV5bestSkg1CRTS6yiQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mechanics-Mechatronics-and-Robotics/ML-2025a/blob/main/PINN_Plates.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "rmq4AfmGqdpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies for Colab\n",
        "!pip install pytorch-lightning clearml\n",
        "\n",
        "import math\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from pytorch_lightning.loggers import TensorBoardLogger\n",
        "from clearml import Task\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from dataclasses import dataclass"
      ],
      "metadata": {
        "id": "Vv0zf7tvdX-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter your code here to implement Step 2 of the logging instruction as it is shown below\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=ZP02U03C6V5ER4K9VWRNZT7EWA5ZTV\n",
        "%env CLEARML_API_SECRET_KEY=BtA5GXZufr6QGpaqhX1GSKPTvaCt56OLqaNqUGLNoxx2Ye8Ctwbui0Ln5OXVnzUgH4I"
      ],
      "metadata": {
        "id": "WzTf35OCdkhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  Theoretical Introduction: Dimensionless PINNs for Parallel Plate Flow"
      ],
      "metadata": {
        "id": "pR6UHeW91jXg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We consider the steady, fully developed flow of an incompressible Newtonian fluid between two infinite parallel plates separated by distance \\(h\\).  \n",
        "The velocity is unidirectional along \\(x\\), varying only in the transverse direction \\(y\\), so the governing equation reduces to:\n",
        "\n",
        "$$\n",
        "\\mu \\frac{d^2 u}{dy^2} = \\frac{dp}{dx}\n",
        "$$\n",
        "\n",
        "where $\\mu$ is dynamic viscosity, $\\frac{dp}{dx}$ â€” constant pressure gradient (typically negative).\n",
        "\n",
        "The **no-slip boundary conditions** are applied at both plates:\n",
        "<!--  -->\n",
        "$$\n",
        "u\\left(-\\tfrac{h}{2}\\right) = 0, \\quad u\\left(\\tfrac{h}{2}\\right) = 0\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## âœ… Nondimensionalization\n",
        "\n",
        "We define dimensionless variables:\n",
        "\n",
        "$$\n",
        "Y = \\frac{y}{h}, \\qquad U = \\frac{u}{U_\\mathrm{ref}}, \\qquad\n",
        "\\Pi = \\frac{h^2}{\\mu U_\\mathrm{ref}} \\left(\\frac{dp}{dx}\\right)\n",
        "$$\n",
        "\n",
        "Substituting into the PDE gives the **dimensionless Poisson equation**:\n",
        "\n",
        "$$\n",
        "\\frac{d^2 U}{dY^2} = \\Pi\n",
        "$$\n",
        "\n",
        "with **boundary conditions**:\n",
        "\n",
        "$$\n",
        "U(-\\tfrac{1}{2}) = 0, \\quad U(\\tfrac{1}{2}) = 0\n",
        "$$\n",
        "\n",
        "The **analytic solution** in nondimensional form is:\n",
        "\n",
        "$$\n",
        "U(Y) = \\frac{\\Pi}{2} \\left( \\tfrac{1}{4} - Y^2 \\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "## âš™ï¸ Physics-Informed Neural Network (PINN) Formulation\n",
        "\n",
        "We approximate $U(Y)$ using a neural network $\\hat{U}(Y)$ and enforce physics via loss minimization.\n",
        "\n",
        "The total loss combines:\n",
        "\n",
        "- **PDE residual loss** â€” enforcing the governing equation  \n",
        "- **Boundary loss** â€” enforcing no-slip at $Y = \\pm \\tfrac{1}{2}$\n",
        "\n",
        "$$\n",
        "\\mathcal{L} =\n",
        "\\underbrace{\n",
        "\\frac{1}{N_r} \\sum_{i=1}^{N_r}\n",
        "\\left|\n",
        "\\frac{d^2 \\hat{U}}{dY^2}(Y_i) - \\Pi\n",
        "\\right|^2\n",
        "}_{\\text{Physics loss}}\n",
        "+\n",
        "\\underbrace{\n",
        "\\frac{1}{N_b} \\sum_{j=1}^{N_b}\n",
        "\\left|\n",
        "\\hat{U}(Y_j) - U_j\n",
        "\\right|^2\n",
        "}_{\\text{Boundary loss}}\n",
        "$$"
      ],
      "metadata": {
        "id": "zfEqnjmA1U3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "u1IQaLWMqjMr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.set_default_dtype(torch.float32)\n",
        "pl.seed_everything(42)\n",
        "\n",
        "# ----------------------------\n",
        "# Config\n",
        "# ----------------------------\n",
        "@dataclass\n",
        "class Config:\n",
        "    # physics (used for physical back-transforms; training is dimensionless)\n",
        "    h: float = 0.001               # we work in Y in [-0.5, 0.5];\n",
        "    mu: float = 0.000001               # we work in Y in [-0.5, 0.5];\n",
        "    dpdx: float = - 100000.0\n",
        "    # training hyperparams\n",
        "    lr: float = 1e-4\n",
        "    epochs: int = 1000\n",
        "    n_colloc_per_pi: int = 128\n",
        "    n_pi_train: int = 60         # number of distinct Î  values in training\n",
        "    n_pi_val: int = 40           # number of distinct Î  values in validation (held out)\n",
        "    pi_min: float = 1.0          # Î  range (training)\n",
        "    pi_max: float = 1.0\n",
        "    # checkpointing\n",
        "    task_name: str = \"PINN_plates_dimless_generalized\"\n",
        "    ckpt_dir: str = \"checkpoints\"\n",
        "    ckpt_name: str = \"pinn_dimless-{epoch:03d}-{val_loss:.6f}\"\n",
        "    # network\n",
        "    layers: tuple = (2, 64, 64, 64, 1)  # input 2 => [Y, Î ]\n",
        "\n",
        "cfg = Config()\n",
        "\n",
        "task = Task.init(\n",
        "    project_name=\"PINN_Project\",   # choose a descriptive project name\n",
        "    task_name=cfg.task_name,  # descriptive task name\n",
        ")\n",
        "\n",
        "# task.connect(params)\n",
        "tb_logger = TensorBoardLogger(\n",
        "    save_dir=\"logs\",  # ClearML will automatically monitor this\n",
        "    name=cfg.task_name,\n",
        "    # version=f\"bs_{HP['batch_size']}_lr_{HP['lr_simclr']}\"\n",
        "  )\n",
        "\n",
        "# ----------------------------\n",
        "# Utilities\n",
        "# ----------------------------\n",
        "def sample_uniform(n, a, b, device):\n",
        "    return (a + (b - a) * torch.rand(n, 1, device=device))\n",
        "\n",
        "def make_grid_y(n, device):\n",
        "    return torch.linspace(-0.5, 0.5, n, device=device).reshape(-1, 1)\n",
        "\n",
        "def generate_family_batch(pi_values, n_colloc_per_pi, device):\n",
        "    \"\"\"\n",
        "    Build collocation and BC batches for a list of Î  values.\n",
        "    For each Î , we create:\n",
        "      - collocation points (Y, Î )\n",
        "      - boundary points at Y = {-0.5, 0.5} with target U=0\n",
        "    Returns a dict of tensors concatenated across all Î .\n",
        "    \"\"\"\n",
        "    Ys = []\n",
        "    Pis = []\n",
        "    Yb = []\n",
        "    Pib = []\n",
        "    Ub = []\n",
        "\n",
        "    for pi in pi_values:\n",
        "        # Collocation: Y in [-0.5, 0.5]\n",
        "        Yc = make_grid_y(n_colloc_per_pi, device)\n",
        "        Pc = torch.full_like(Yc, fill_value=pi.item())\n",
        "        Ys.append(Yc)\n",
        "        Pis.append(pc := Pc)  # noqa: F841\n",
        "\n",
        "        # Boundary (two points per Î )\n",
        "        Y_bc = torch.tensor([[-0.5], [0.5]], device=device, dtype=torch.float32)\n",
        "        P_bc = torch.full_like(Y_bc, fill_value=pi.item())\n",
        "        U_bc = torch.zeros_like(Y_bc)\n",
        "        Yb.append(Y_bc)\n",
        "        Pib.append(P_bc)\n",
        "        Ub.append(U_bc)\n",
        "\n",
        "    Y_colloc = torch.cat(Ys, dim=0)\n",
        "    Pi_colloc = torch.cat(Pis, dim=0)\n",
        "    Y_bc = torch.cat(Yb, dim=0)\n",
        "    Pi_bc = torch.cat(Pib, dim=0)\n",
        "    U_bc = torch.cat(Ub, dim=0)\n",
        "\n",
        "    X_colloc = torch.cat([Y_colloc, Pi_colloc], dim=1)  # [N, 2]\n",
        "    X_bc = torch.cat([Y_bc, Pi_bc], dim=1)              # [2*len(pi_values), 2]\n",
        "\n",
        "    return {\n",
        "        \"X_colloc\": X_colloc,\n",
        "        \"Y_colloc\": Y_colloc,   # keep Y separately for derivatives\n",
        "        \"X_bc\": X_bc,\n",
        "        \"U_bc\": U_bc\n",
        "    }\n",
        "\n",
        "def split_pi_train_val(pi_min, pi_max, n_train, n_val, device):\n",
        "    # Sample a superset and split into disjoint train/val sets\n",
        "    pis_all = torch.linspace(pi_min, pi_max, steps=n_train + n_val + 4, device=device)\n",
        "    # pick train indices and val indices disjointly (e.g., every other)\n",
        "    train_idx = torch.arange(0, n_train, device=device)\n",
        "    val_idx = torch.arange(n_train, n_train + n_val, device=device)\n",
        "    pi_train = pis_all[train_idx]\n",
        "    pi_val = pis_all[val_idx]\n",
        "    return pi_train.reshape(-1, 1), pi_val.reshape(-1, 1)\n",
        "\n",
        "# ----------------------------\n",
        "# Dataset / DataModule\n",
        "# ----------------------------\n",
        "class FamilyDataset(torch.utils.data.Dataset):\n",
        "    \"\"\"Single-item dataset that returns a prebuilt batch (for Lightning convenience).\"\"\"\n",
        "    def __init__(self, batch_dict):\n",
        "        super().__init__()\n",
        "        self.batch_dict = batch_dict\n",
        "\n",
        "    def __len__(self):\n",
        "        return 1\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.batch_dict\n",
        "\n",
        "class PINNDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, cfg: Config, device=\"cpu\"):\n",
        "        super().__init__()\n",
        "        self.cfg = cfg\n",
        "        self.device_ = device\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        device = self.device_\n",
        "        # Disjoint Î  sets: train vs val (held-out Î )\n",
        "        pi_train, pi_val = split_pi_train_val(cfg.pi_min, cfg.pi_max, cfg.n_pi_train, cfg.n_pi_val, device)\n",
        "        self.train_batch = generate_family_batch(pi_train, cfg.n_colloc_per_pi, device)\n",
        "        self.val_batch = generate_family_batch(pi_val,   cfg.n_colloc_per_pi, device)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(FamilyDataset(self.train_batch), batch_size=1, shuffle=False)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(FamilyDataset(self.val_batch), batch_size=1, shuffle=False)\n",
        "\n",
        "# ----------------------------\n",
        "# PINN model (dimensionless)\n",
        "# ----------------------------\n",
        "class PINN(pl.LightningModule):\n",
        "    \"\"\"\n",
        "    Network takes X = [Y, Î ] and predicts U_hat(Y, Î ).\n",
        "    PDE residual uses d^2 U / dY^2 = Î  (dimensionless).\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, lr):\n",
        "        super().__init__()\n",
        "        self.save_hyperparameters(ignore=[\"layers\"])  # store lr\n",
        "        self.lr = lr\n",
        "        self.net = self._build_mlp(layers)\n",
        "        self.act = nn.Tanh()\n",
        "\n",
        "    def _build_mlp(self, sizes):\n",
        "        layers = []\n",
        "        for i in range(len(sizes)-1):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "        return nn.ModuleList(layers)\n",
        "\n",
        "    def forward(self, X):\n",
        "        # X = [Y, Î ]\n",
        "        out = X\n",
        "        for layer in self.net[:-1]:\n",
        "            out = self.act(layer(out))\n",
        "        out = self.net[-1](out)\n",
        "        return out  # U_hat\n",
        "\n",
        "    # def _second_deriv_wrt_Y(self, X, Y_only):\n",
        "    #     \"\"\"\n",
        "    #     Compute d^2U/dY^2 by autograd.\n",
        "    #     - X requires grad for Y dimension; Î  is treated as constant (no derivative).\n",
        "    #     \"\"\"\n",
        "    #     X = X.clone().detach().requires_grad_(True)\n",
        "    #     U = self.forward(X)\n",
        "\n",
        "    #     # gradient wrt inputs [dU/dY, dU/dÎ ]\n",
        "    #     grads = torch.autograd.grad(U, X, grad_outputs=torch.ones_like(U), create_graph=True, retain_graph=True)[0]\n",
        "    #     dU_dY = grads[:, :1]  # first column corresponds to Y\n",
        "\n",
        "    #     grads2 = torch.autograd.grad(dU_dY, X, grad_outputs=torch.ones_like(dU_dY), create_graph=True, retain_graph=True)[0]\n",
        "    #     d2U_dY2 = grads2[:, :1]\n",
        "    #     return d2U_dY2\n",
        "\n",
        "    def _second_deriv_wrt_Y(self, X, Y_only):\n",
        "        \"\"\"\n",
        "        Compute dÂ²U/dYÂ² - FIXED VERSION\n",
        "        \"\"\"\n",
        "        # Create a copy that requires gradients\n",
        "        X_temp = X.clone().requires_grad_(True)\n",
        "\n",
        "        # Forward pass\n",
        "        U = self.forward(X_temp)\n",
        "\n",
        "        # First derivative - only wrt Y (first column)\n",
        "        dU_dY = torch.autograd.grad(\n",
        "            U, X_temp,\n",
        "            grad_outputs=torch.ones_like(U),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0][:, 0:1]  # Only derivative wrt Y\n",
        "\n",
        "        # Second derivative\n",
        "        d2U_dY2 = torch.autograd.grad(\n",
        "            dU_dY, X_temp,\n",
        "            grad_outputs=torch.ones_like(dU_dY),\n",
        "            create_graph=True,\n",
        "            retain_graph=True\n",
        "        )[0][:, 0:1]  # Only derivative wrt Y\n",
        "\n",
        "        return d2U_dY2\n",
        "\n",
        "\n",
        "    def _pde_residual(self, batch):\n",
        "        Xc = batch[\"X_colloc\"]  # [N, 2] = [Y, Î ]\n",
        "        Y  = batch[\"Y_colloc\"]  # [N, 1]\n",
        "        Pi = Xc[:, 1:2]\n",
        "        U_YY = self._second_deriv_wrt_Y(Xc, Y)\n",
        "        res = U_YY - Pi\n",
        "        return res\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        # PDE residual loss\n",
        "        res = self._pde_residual(batch)\n",
        "        pde_loss = torch.mean(res**2)\n",
        "\n",
        "        # Boundary loss\n",
        "        Xb = batch[\"X_bc\"]\n",
        "        Ub_tgt = batch[\"U_bc\"]\n",
        "        Ub_pred = self.forward(Xb)\n",
        "        bc_loss = nn.functional.mse_loss(Ub_pred, Ub_tgt)\n",
        "\n",
        "        loss = pde_loss + bc_loss\n",
        "        self.log_dict({\"train_pde\": pde_loss, \"train_bc\": bc_loss, \"train_loss\": loss}, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        # Ensure autograd is enabled during validation (Lightning disables it by default)\n",
        "        with torch.enable_grad():\n",
        "            res = self._pde_residual(batch)\n",
        "            pde_loss = torch.mean(res**2)\n",
        "            Xb = batch[\"X_bc\"]\n",
        "            Ub_tgt = batch[\"U_bc\"]\n",
        "            Ub_pred = self.forward(Xb)\n",
        "            bc_loss = nn.functional.mse_loss(Ub_pred, Ub_tgt)\n",
        "            val_loss = pde_loss + bc_loss\n",
        "\n",
        "        self.log_dict({\"val_pde\": pde_loss, \"val_bc\": bc_loss, \"val_loss\": val_loss}, prog_bar=True)\n",
        "        return val_loss\n",
        "\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
        "\n",
        "# ----------------------------\n",
        "# Train\n",
        "# ----------------------------\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "dm = PINNDataModule(cfg, device=device)\n",
        "dm.setup()\n",
        "\n",
        "model = PINN(layers=cfg.layers, lr=cfg.lr)\n",
        "\n",
        "ckpt_cb = ModelCheckpoint(\n",
        "    dirpath=cfg.ckpt_dir,\n",
        "    filename=cfg.ckpt_name,\n",
        "    monitor=\"val_loss\",\n",
        "    save_top_k=1,\n",
        "    mode=\"min\",\n",
        "    # save_last=True\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=cfg.epochs,\n",
        "    accelerator=\"auto\",\n",
        "    callbacks=[ckpt_cb],\n",
        "    log_every_n_steps=100,\n",
        "    check_val_every_n_epoch=100\n",
        ")\n",
        "\n",
        "trainer.fit(model, datamodule=dm)\n",
        "\n",
        "print(\"Best checkpoint:\", ckpt_cb.best_model_path)\n"
      ],
      "metadata": {
        "id": "OSNGxk4Qu5oL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %% Helper: physical prediction for given (h, mu, dpdx)\n",
        "@torch.no_grad()\n",
        "def predict_physical_profile(model, h, mu, dpdx, n_points=200, device=\"cpu\"):\n",
        "    \"\"\"\n",
        "    Returns y [m], u [m/s] predicted by the trained dimensionless PINN, for a given physical case.\n",
        "    \"\"\"\n",
        "    # reference velocity & Pi\n",
        "    U_ref = (h**2) / (2.0 * mu) * abs(dpdx)\n",
        "    Pi = (h**2) / (mu * U_ref) * (-dpdx)  # positive for dpdx<0\n",
        "\n",
        "    # build inputs\n",
        "    Y = torch.linspace(-0.5, 0.5, n_points, device=device).reshape(-1, 1)\n",
        "    Pi_col = torch.full_like(Y, fill_value=float(Pi))\n",
        "    X = torch.cat([Y, Pi_col], dim=1)\n",
        "\n",
        "    model = model.to(device)\n",
        "    U_hat = model(X).squeeze(1).cpu().numpy()\n",
        "    y = (Y.squeeze(1).cpu().numpy()) * h\n",
        "    u = U_hat * U_ref\n",
        "    return y, u, U_ref, Pi\n",
        "\n",
        "# Example: use the same h, mu, dpdx you used originally (units: m, Pa*s, Pa/m)\n",
        "h = 0.001\n",
        "mu = 0.001\n",
        "dpdx = -1.0e4\n",
        "\n",
        "best_model = PINN.load_from_checkpoint(ckpt_cb.best_model_path, layers=cfg.layers, lr=cfg.lr)\n",
        "y_phys, u_phys, U_ref, Pi_used = predict_physical_profile(best_model, h=h, mu=mu, dpdx=dpdx, device=device)\n",
        "\n",
        "print(f\"Used U_ref={U_ref:.6e}, Pi={Pi_used:.4f}, y range [{y_phys.min():.3e}, {y_phys.max():.3e}] m\")\n",
        "print(\"Sample u(m/s):\", u_phys[:5])\n"
      ],
      "metadata": {
        "id": "i5Gx0T4Pu5k7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation grid\n",
        "n_points = 100\n",
        "Y_grid = torch.linspace(-0.5, 0.5, n_points, device=device).reshape(-1,1)\n",
        "\n",
        "Pi_values = [0.1, 1.0, 5.0, 10.0]\n",
        "\n",
        "results_table = []\n",
        "\n",
        "plt.figure(figsize=(10,6))\n",
        "for pi in Pi_values:\n",
        "    Pi_grid = torch.full_like(Y_grid, fill_value=pi)\n",
        "    X_grid = torch.cat([Y_grid, Pi_grid], dim=1)\n",
        "\n",
        "    # PINN prediction\n",
        "    with torch.no_grad():\n",
        "        U_pred = best_model(X_grid).cpu().numpy().flatten()\n",
        "\n",
        "    # Analytical solution\n",
        "    U_analytical = (pi/2)*(0.25 - Y_grid.cpu().numpy().flatten()**2)\n",
        "\n",
        "    # Calculate errors at key points\n",
        "    idx_center = n_points//2        # Y=0\n",
        "    idx_top = 0                     # Y=-0.5\n",
        "    idx_bottom = n_points-1         # Y=0.5\n",
        "\n",
        "    error_center = abs(U_pred[idx_center] - U_analytical[idx_center])\n",
        "    error_top    = abs(U_pred[idx_top] - U_analytical[idx_top])\n",
        "    error_bottom = abs(U_pred[idx_bottom] - U_analytical[idx_bottom])\n",
        "\n",
        "    results_table.append({\n",
        "        \"Pi\": pi,\n",
        "        \"U_pr(Y=0)\": U_pred[idx_center],\n",
        "        \"U_an(Y=0)\": U_analytical[idx_center],\n",
        "        \"Error(Y=0)\": error_center,\n",
        "        \"U_pr(Y=-0.5)\": U_pred[idx_top],\n",
        "        \"U_an(Y=-0.5)\": U_analytical[idx_top],\n",
        "        \"Error(Y=-0.5)\": error_top,\n",
        "        \"U_pr(Y=0.5)\": U_pred[idx_bottom],\n",
        "        \"U_an(Y=0.5)\": U_analytical[idx_bottom],\n",
        "        \"Error(Y=0.5)\": error_bottom\n",
        "    })\n",
        "\n",
        "    # Plot velocity profiles\n",
        "    plt.plot(Y_grid.cpu(), U_pred, '--', label=f\"PINN Î ={pi}\")\n",
        "    plt.plot(Y_grid.cpu(), U_analytical, '-', label=f\"Analytical Î ={pi}\")\n",
        "\n",
        "plt.xlabel(\"Y\")\n",
        "plt.ylabel(\"U(Y, Î )\")\n",
        "plt.title(\"PINN vs Analytical Couette Flow Velocity Profiles\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "2ij3HLsi4MPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "df_results = pd.DataFrame(results_table)\n",
        "pd.set_option(\"display.float_format\", \"{:.6f}\".format)\n",
        "print(df_results)\n"
      ],
      "metadata": {
        "id": "-tPX7lC275Gi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Inspect one batch from train and val ---\n",
        "\n",
        "dm = PINNDataModule(cfg, device=device)\n",
        "dm.setup()\n",
        "\n",
        "train_loader = dm.train_dataloader()\n",
        "val_loader = dm.val_dataloader()\n",
        "\n",
        "train_batch = next(iter(train_loader))\n",
        "val_batch = next(iter(val_loader))\n",
        "\n",
        "print(\"\\n=== TRAIN BATCH ===\")\n",
        "for k, v in train_batch.items():\n",
        "    print(f\"{k}: shape={v.shape}\")\n",
        "    print(v[0,:5])  # print first 10 rows for brevity\n",
        "\n",
        "print(\"\\n=== VAL BATCH ===\")\n",
        "for k, v in val_batch.items():\n",
        "    print(f\"{k}: shape={v.shape}\")\n",
        "    print(v[0,:5])\n"
      ],
      "metadata": {
        "id": "JvbQlWK_Gkx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task.close()"
      ],
      "metadata": {
        "id": "_a8VvG3p4YXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
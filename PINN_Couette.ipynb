{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPXUDhtLY+7IPB3Y3MH6fSk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mechanics-Mechatronics-and-Robotics/ML-2025a/blob/main/PINN_Couette.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialization"
      ],
      "metadata": {
        "id": "rmq4AfmGqdpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Install dependencies for Colab\n",
        "!pip install pytorch-lightning clearml\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning.callbacks import ModelCheckpoint\n",
        "from clearml import Task\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "Vv0zf7tvdX-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Enter your code here to implement Step 2 of the logging instruction as it is shown below\n",
        "%env CLEARML_WEB_HOST=https://app.clear.ml/\n",
        "%env CLEARML_API_HOST=https://api.clear.ml\n",
        "%env CLEARML_FILES_HOST=https://files.clear.ml\n",
        "%env CLEARML_API_ACCESS_KEY=ZP02U03C6V5ER4K9VWRNZT7EWA5ZTV_\n",
        "%env CLEARML_API_SECRET_KEY=BtA5GXZufr6QGpaqhX1GSKPTvaCt56OLqaNqUGLNoxx2Ye8Ctwbui0Ln5OXVnzUgH4I_"
      ],
      "metadata": {
        "id": "WzTf35OCdkhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Theoretical Introduction to PINNs for Parallel Plates Flow\n",
        "\n",
        "We consider the steady flow of an incompressible Newtonian fluid between two infinite parallel plates separated by a gap $h$. Assuming the flow is unidirectional along the $x$-axis and the velocity varies only in the transverse coordinate $y$, the flow velocity $u(y)$ satisfies a simplified Navier-Stokes equation:\n",
        "\n",
        "$$\n",
        "\\mu \\frac{d^2 u}{dy^2} = \\frac{dp}{dx}\n",
        "$$\n",
        "\n",
        "where $\\mu$ is the dynamic viscosity,  $\\frac{dp}{dx}$ is the constant pressure gradient driving the flow.\n",
        "\n",
        "The fluid adheres to the no-slip boundary conditions on the plates:\n",
        "\n",
        "$$\n",
        "u\\left(-\\frac{h}{2}\\right) = 0, \\quad u\\left(\\frac{h}{2}\\right) = 0\n",
        "$$\n",
        "\n",
        "The analytical solution to this boundary value problem is the classical parabolic velocity profile:\n",
        "\n",
        "$$\n",
        "u(y) = \\frac{1}{2 \\mu} \\frac{dp}{dx} \\left(\\frac{h^2}{4} - y^2 \\right)\n",
        "$$\n",
        "\n",
        "---\n",
        "\n",
        "### Physics-Informed Neural Networks (PINNs)\n",
        "\n",
        "PINNs approximate the solution $u(y)$ with a neural network that directly incorporates the governing differential equation and boundary conditions into the loss function. Instead of learning from data alone, PINNs minimize:\n",
        "\n",
        "- a **PDE residual loss** to enforce the differential equation at sampled collocation points $y_i$,\n",
        "- and a **boundary condition loss** to satisfy $u(\\pm h/2)=0$.\n",
        "\n",
        "The loss function combines these terms:\n",
        "\n",
        "$$\n",
        "\\mathcal{L} =\n",
        "\\underbrace{\n",
        "    \\frac{1}{N_r} \\sum_{i=1}^{N_r} \\left| \\mu \\frac{d^2 \\hat{u}}{dy^2}(y_i) - \\frac{dp}{dx} \\right|^2\n",
        "}_{\\text{PDE residual loss}}\n",
        "+\n",
        "\\underbrace{\n",
        "    \\frac{1}{N_b} \\sum_{j=1}^{N_b} \\left| \\hat{u}(y_j) - u_j \\right|^2\n",
        "}_{\\text{Boundary loss}}\n",
        "$$\n",
        "\n",
        "where $\\hat{u}$ is the neural network prediction, $N_r$ collocation points inside the domain, and $N_b$ boundary points.\n",
        "\n",
        "---\n",
        "\n",
        "This approach enables the neural network to learn solutions that satisfy physical laws inherently, requiring fewer data and guaranteeing physically plausible outputs. The example notebook implements this PINN framework in PyTorch Lightning, comparing the learned velocity profile with the exact analytical solution for validation.\n"
      ],
      "metadata": {
        "id": "dn8--mUCye6F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "u1IQaLWMqjMr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzifHeZDdLhT"
      },
      "outputs": [],
      "source": [
        "# Initialize ClearML\n",
        "task = Task.init(project_name='PINN_Project', task_name='Parallel Plates Flow PINN')\n",
        "\n",
        "# PINN Model (a simple fully-connected NN)\n",
        "class PINN(pl.LightningModule):\n",
        "    def __init__(self, layers, mu, dpdx):\n",
        "        super().__init__()\n",
        "        self.mu = mu           # viscosity\n",
        "        self.dpdx = dpdx       # pressure gradient (can be learnable)\n",
        "        layer_list = []\n",
        "        for i in range(len(layers)-1):\n",
        "            layer_list.append(nn.Linear(layers[i], layers[i+1]))\n",
        "        self.layers = nn.ModuleList(layer_list)\n",
        "        self.activation = nn.Tanh()\n",
        "\n",
        "    def forward(self, y):\n",
        "        out = y\n",
        "        for i in range(len(self.layers)-1):\n",
        "            out = self.activation(self.layers[i](out))\n",
        "        out = self.layers[-1](out)\n",
        "        return out\n",
        "\n",
        "    def pinn_residual(self, y):\n",
        "        \"\"\"Calculate PDE residual: mu * u'' - dp/dx\"\"\"\n",
        "        y = y.requires_grad_(True)\n",
        "        u = self.forward(y)\n",
        "        u_y = torch.autograd.grad(u, y, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
        "        u_yy = torch.autograd.grad(u_y, y, grad_outputs=torch.ones_like(u_y), create_graph=True)[0]\n",
        "        residual = self.mu * u_yy - self.dpdx\n",
        "        return residual\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        y_bc, u_bc = batch['y_bc'], batch['u_bc']\n",
        "        y_colloc = batch['y_colloc']\n",
        "\n",
        "        # Boundary condition loss (no-slip)\n",
        "        u_pred_bc = self.forward(y_bc)\n",
        "        bc_loss = nn.functional.mse_loss(u_pred_bc, u_bc)\n",
        "        self.log('bc_loss', bc_loss)\n",
        "\n",
        "        # PDE residual loss\n",
        "        residual = self.pinn_residual(y_colloc)\n",
        "        pde_loss = torch.mean(residual**2)\n",
        "        self.log('pde_loss', pde_loss)\n",
        "\n",
        "        loss = bc_loss + pde_loss\n",
        "        self.log('train_loss', loss)\n",
        "        return loss\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-3)\n",
        "\n",
        "# Data preparation (simple sampling for training)\n",
        "def generate_data(n_bc=2, n_colloc=100):\n",
        "    # Domain between y = -h/2 and h/2\n",
        "    h = 1.0\n",
        "    y_bc = torch.tensor([[-h/2], [h/2]], dtype=torch.float32)  # BC points\n",
        "    u_bc = torch.zeros_like(y_bc)                              # u=0 at plates\n",
        "    y_colloc = torch.linspace(-h/2, h/2, n_colloc).reshape(-1,1).float()  # collocation points (PDE residual)\n",
        "\n",
        "    return {'y_bc': y_bc, 'u_bc': u_bc, 'y_colloc': y_colloc, 'h': h}\n",
        "\n",
        "# Lightning DataModule for clean batch management\n",
        "class PINNDataModule(pl.LightningDataModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.data = generate_data()\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        # Return a data loader with batch size 1 that yields the full dict\n",
        "        return torch.utils.data.DataLoader([self.data], batch_size=1)\n",
        "\n",
        "# Instantiate model and data module\n",
        "mu = 1.0    # dynamic viscosity\n",
        "dpdx = -1.0 # constant pressure gradient\n",
        "\n",
        "model = PINN(layers=[1, 20, 20, 1], mu=mu, dpdx=dpdx)\n",
        "data_module = PINNDataModule()\n",
        "\n",
        "# Save a checkpoint every 10 epochs\n",
        "checkpoint_callback = ModelCheckpoint(\n",
        "    dirpath='my_checkpoints/',\n",
        "    filename='pinn-{epoch:02d}-{train_loss:.4f}',\n",
        "    save_top_k=1,            # only keep the top 3 checkpoints\n",
        "    monitor='train_loss',    # or your preferred validation metric\n",
        "    mode='min',\n",
        "    every_n_epochs=50        # <<--- only every 10 epochs\n",
        ")\n",
        "\n",
        "trainer = pl.Trainer(\n",
        "    max_epochs=600,\n",
        "    accelerator='auto',\n",
        "    callbacks=[checkpoint_callback],\n",
        "    log_every_n_steps=10\n",
        ")\n",
        "\n",
        "# Train\n",
        "trainer.fit(model, datamodule=data_module)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Plot PINN vs Analytical\n",
        "\n",
        "h = data_module.data['h']\n",
        "y_vals = np.linspace(-h/2, h/2, 200).reshape(-1,1).astype(np.float32)\n",
        "y_torch = torch.tensor(y_vals)\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    u_pred = model(y_torch).cpu().numpy().flatten()\n",
        "\n",
        "def analytical_solution(y, mu, dpdx, h):\n",
        "    return (1/(2*mu)) * (-dpdx) * ((h**2)/4 - y**2)\n",
        "\n",
        "\n",
        "u_analytical = analytical_solution(y_vals, mu, dpdx, h).flatten()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(y_vals, u_pred, label='PINN Prediction', linewidth=2)\n",
        "plt.plot(y_vals, u_analytical, '--', label='Analytical Solution', linewidth=2)\n",
        "plt.xlabel('y')\n",
        "plt.ylabel('Velocity u(y)')\n",
        "plt.title('Velocity Profile between Parallel Plates')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(y_vals, u_pred, label='PINN Prediction', linewidth=2)\n",
        "plt.plot(y_vals, u_analytical, '--', label='Analytical Solution', linewidth=2)\n",
        "plt.xlabel('y')\n",
        "plt.ylabel('Velocity u(y)')\n",
        "plt.title('Velocity Profile between Parallel Plates')\n",
        "plt.yscale('log')   # <-- set y-axis to logarithmic scale\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "error = np.abs(u_pred - u_analytical) + 1e-8  # add a small value to avoid log(0)\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(y_vals, error, label='Absolute Error', linewidth=2)\n",
        "plt.xlabel('y')\n",
        "plt.ylabel('Absolute Error')\n",
        "plt.title('Error between PINN Prediction and Analytical Solution')\n",
        "plt.yscale('log')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "acXSQ5ELpk0H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "task.close()"
      ],
      "metadata": {
        "id": "_a8VvG3p4YXa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}